{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baa019b4-b1b7-4420-8c4a-a42cead0d2a0",
   "metadata": {},
   "source": [
    "# Spider\n",
    "\n",
    "\n",
    "### What is \"class\"?\n",
    "\n",
    "A class is a programming construct that serves as a blueprint for creating objects. Objects are instances of a class and can have attributes (characteristics) and methods (functions) associated with them. Classes enable the organization and encapsulation of code, allowing for the creation of reusable and structured code in object-oriented programming paradigms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3e5495-d607-41ea-ba55-e41eae1602c9",
   "metadata": {},
   "source": [
    "# Real Estate Web Scraping Summary\n",
    "\n",
    "This Python script utilizes the Scrapy framework to scrape real estate data from the website www.emlakjet.com for various districts in Istanbul. The spider, named \"Real estate_Spider,\" extracts information such as property titles, prices, links, and building ages for properties listed in specific districts.\n",
    "\n",
    "## Spider Functionality\n",
    "\n",
    "1. **Initialization:**\n",
    "    - The spider class `Realestate_Spider` is defined, including class variables for district names, titles, prices, links, and building ages.\n",
    "\n",
    "2. **Request Generation:**\n",
    "    - The `start_requests` method generates requests for each district's real estate listings on www.emlakjet.com, creating URLs based on the district names.\n",
    "\n",
    "3. **Parsing Listings:**\n",
    "    - The `parse1` method extracts property titles, cleans HTML tags, and appends the cleaned titles to the `titles` list.\n",
    "    - It also extracts property prices and appends them to the `prices` list.\n",
    "    - Property links are extracted and appended to the `links` list.\n",
    "    - For each property link, a new request is followed to the `parse2` method.\n",
    "\n",
    "4. **Additional Property Details:**\n",
    "    - The `parse2` method extracts building ages from individual property pages and appends them to the `age_list`.\n",
    "\n",
    "## CrawlerProcess Initialization\n",
    "\n",
    "- A `CrawlerProcess` object is created to manage the scraping process.\n",
    "\n",
    "## Start Crawling\n",
    "\n",
    "- The spider class `Realestate_Spider` is passed to the `process.crawl` method to initiate the scraping.\n",
    "- The scraping process is started with `process.start()`.\n",
    "\n",
    "## Result Storage\n",
    "\n",
    "- The extracted data (titles, prices, links, and building ages) is stored within the spider class as class variables.\n",
    "- Users can access the scraped data after the crawling process is complete by referencing the class variables.\n",
    "\n",
    "Note: Ensure you run this code in a Scrapy-enabled environment for successful execution.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa4543d-bfca-4d45-bf55-94f38fece0d6",
   "metadata": {},
   "source": [
    "### Basic structure of spider class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb71d827-5d0a-4416-b284-9f1cae3a3c22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "import re\n",
    "\n",
    "class Realestate_Spider(scrapy.Spider):\n",
    "    name = \"Real estate_Spider\"\n",
    "\n",
    "    def start_requests(self):\n",
    "        yield scrapy.Request(url = 'https://www.emlakjet.com', callback = self.parse1)\n",
    "        \n",
    "    def parse1(self, response):\n",
    "        titles_in = response.xpath('//h4/text()').extract()\n",
    "        for i in titles_in:\n",
    "            titles.append(i)\n",
    "                                      \n",
    "titles = []\n",
    "\n",
    "process = CrawlerProcess()\n",
    "process.crawl(Realestate_Spider)\n",
    "process.start()\n",
    "\n",
    "titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56161ab0-9d1a-4e8b-8f3b-7871236459ce",
   "metadata": {},
   "source": [
    "### Our spider class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fba0a4-647b-45f0-9357-5058e5a194ad",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "import re\n",
    "\n",
    "class Realestate_Spider(scrapy.Spider):\n",
    "    name = \"Real estate_Spider\"\n",
    "    \n",
    "    district_list = [\"uskudar\", \"fatih\", \"umraniye\", \"kadikoy\",\"sariyer\",\"zeytinburnu\",\"beylikduzu\",\"maltepe\"]        \n",
    "    titles = []\n",
    "    prices = []\n",
    "    links = []\n",
    "    age_list = []\n",
    "\n",
    "    def start_requests(self):\n",
    "        for district in self.district_list:\n",
    "            link1 = 'https://www.emlakjet.com/satilik-konut/istanbul-' + district        \n",
    "            yield scrapy.Request(url=link1, callback=self.parse1)\n",
    "\n",
    "    def parse1(self, response):        \n",
    "        titles_in = response.xpath('//*[@id=\"listing-search-wrapper\"]/div/a/div[3]/div/div[1]/h3/text()').extract()           \n",
    "        for i in titles_in:\n",
    "            self.titles.append(i)        \n",
    "            \n",
    "        prices_in = response.xpath(\"//*[@id='listing-search-wrapper']/div/a/div[3]/div/div[3]/div/p/span/span/text()\").extract()\n",
    "        for i in prices_in:\n",
    "            self.prices.append(i)\n",
    "\n",
    "        links_in = response.xpath(\"//*[@id='listing-search-wrapper']/div[@class='_3qUI9q']/a/@href\").extract()\n",
    "\n",
    "        for i in links_in:\n",
    "            first_part_url = 'https://www.emlakjet.com/'\n",
    "            link2 = first_part_url + i\n",
    "            self.links.append(link2)\n",
    "            \n",
    "            yield response.follow(url = link2,  callback = self.parse2)\n",
    "            \n",
    "    def parse2(self, response):\n",
    "        building_age = response.xpath(\"//*[@id='bilgiler']/div/div[2]/div/div[1]/div[2]/div[5]/div[2]/text()\").extract()\n",
    "        for i in building_age:\n",
    "            self.age_list.append(i)\n",
    "            \n",
    "\n",
    "# Create a CrawlerProcess\n",
    "process = CrawlerProcess()\n",
    "\n",
    "# Start the crawling process by passing the spider class, not an instance\n",
    "process.crawl(Realestate_Spider)\n",
    "\n",
    "# Start the process\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c7d0bf-9cd6-45b3-81ea-5006822adbcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Access the titles after the crawling process is complete\n",
    "titles = Realestate_Spider.titles\n",
    "prices = Realestate_Spider.prices\n",
    "links = Realestate_Spider.links\n",
    "age_list = Realestate_Spider.age_list\n",
    "\n",
    "print(len(titles),len(prices),len(links),len(age_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41320cf9-8c4d-4474-821e-0606faf34617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dict_real_estate = {'title':titles, 'price':prices, 'link': links, 'age': age_list}\n",
    "data_real_estate = pd.DataFrame(dict_real_estate)\n",
    "data_real_estate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a382b2b4-d702-4157-bc4c-b7657af11dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_real_estate.to_excel(\"data_real_estate.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2705c1ae-47f0-4b20-833c-44604141ae0f",
   "metadata": {},
   "source": [
    "### Including more-than-one pages for the districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b13d613-1395-4352-be02-cbfa1d556f07",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "import re\n",
    "\n",
    "class Realestate_Spider(scrapy.Spider):\n",
    "    name = \"Real estate_Spider\"\n",
    "    \n",
    "    district_list = [\"uskudar\"]        \n",
    "    titles = []\n",
    "    prices = []\n",
    "    links = []\n",
    "    age_list = []\n",
    "\n",
    "    def start_requests(self):\n",
    "        for district in self.district_list:\n",
    "            link1 = 'https://www.emlakjet.com/satilik-konut/istanbul-' + district\n",
    "            yield scrapy.Request(url=link1, callback=self.parse0)\n",
    "                \n",
    "    def parse0(self, response):\n",
    "        number_of_pages = int(response.xpath('//*[@id=\"listing-search-wrapper\"]/div/div[1]/ul/li[7]/div/a/text()').extract()[0])\n",
    "        for district in self.district_list:\n",
    "            for i in range(1,number_of_pages+1):\n",
    "                link1_5 = 'https://www.emlakjet.com/satilik-konut/istanbul-' + district + \"/\" + str(i)\n",
    "                yield response.follow(url = link1_5,  callback = self.parse1)\n",
    "\n",
    "    def parse1(self, response):        \n",
    "        titles_in = response.xpath('//*[@id=\"listing-search-wrapper\"]/div/a/div[3]/div/div[1]/h3/text()').extract()           \n",
    "        for i in titles_in:\n",
    "            self.titles.append(i)        \n",
    "            \n",
    "        prices_in = response.xpath(\"//*[@id='listing-search-wrapper']/div/a/div[3]/div/div[3]/div/p/span/span/text()\").extract()\n",
    "        for i in prices_in:\n",
    "            self.prices.append(i)\n",
    "\n",
    "        links_in = response.xpath(\"//*[@id='listing-search-wrapper']/div[@class='_3qUI9q']/a/@href\").extract()\n",
    "\n",
    "        for i in links_in:\n",
    "            first_part_url = 'https://www.emlakjet.com/'\n",
    "            link2 = first_part_url + i\n",
    "            self.links.append(link2)\n",
    "            \n",
    "            yield response.follow(url = link2,  callback = self.parse2)\n",
    "            \n",
    "    def parse2(self, response):\n",
    "        building_age = response.xpath(\"//*[@id='bilgiler']/div/div[2]/div/div[1]/div[2]/div[5]/div[2]/text()\").extract()\n",
    "        for i in building_age:\n",
    "            self.age_list.append(i)\n",
    "            \n",
    "\n",
    "# Create a CrawlerProcess\n",
    "process = CrawlerProcess()\n",
    "\n",
    "# Start the crawling process by passing the spider class, not an instance\n",
    "process.crawl(Realestate_Spider)\n",
    "\n",
    "# Start the process\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aaeee4-fbc7-4d5c-ac47-67a5b2c3771d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Access the titles after the crawling process is complete\n",
    "titles = Realestate_Spider.titles\n",
    "prices = Realestate_Spider.prices\n",
    "links = Realestate_Spider.links\n",
    "age_list = Realestate_Spider.age_list\n",
    "\n",
    "print(len(titles),len(prices),len(links),len(age_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0ff197-89b1-415c-bef8-6b6df8964681",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
