{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lasting-strip",
   "metadata": {},
   "source": [
    "# Bayesian Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aba32c",
   "metadata": {},
   "source": [
    "While preparing codes, I have utilized following source: https://app.datacamp.com/learn/courses/bayesian-data-analysis-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a256fc5f-2b02-481d-8753-df302ce5c9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pymc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0612cd63-4efc-4fae-b505-6a4becc5775e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-roads",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset('iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fe2ec4-79ed-407e-b00f-cffa88c8be17",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dadfdf",
   "metadata": {},
   "source": [
    "The Iris flower data set is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper The use of multiple measurements in taxonomic problems. It is sometimes called Anderson's Iris data set because Edgar Anderson collected the data to quantify the morphologic variation of Iris flowers of three related species. The data set consists of 50 samples from each of three species of Iris (Iris Setosa, Iris virginica, and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-cisco",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-hazard",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"sepal_length ~ sepal_width\"\n",
    "\n",
    "with pm.Model() as model_1:\n",
    "    \n",
    "    pm.GLM.from_formula(formula, data=iris)\n",
    "    trace_1 = pm.sample(draws=1000, tune=500, chains=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-inventory",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pm.traceplot(trace_1 ,figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-visitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.forestplot(trace_1, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-conditions",
   "metadata": {},
   "source": [
    "For other arguments of pmyc3 plots, please visit: https://pymc3-testing.readthedocs.io/en/rtd-docs/api/plots.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(trace_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f23e089",
   "metadata": {},
   "source": [
    "#### For the intercept (as an example):\n",
    "- **mean**: The mean (average) value of the intercept is 6.522.\n",
    "- **sd (Standard Deviation)**: The standard deviation of the intercept is 0.491, indicating the spread of the intercept's values.\n",
    "- **hdi_3%**: The lower bound of the Highest Density Interval (HDI) for the intercept is 5.626. This represents the lower end of the interval within which 94% of the values lie.\n",
    "- **hdi_97%**: The upper bound of the HDI for the intercept is 7.466. This represents the upper end of the interval within which 94% of the values lie.\n",
    "- **mcse_mean (Monte Carlo Standard Error for mean)**: The MCSE for the mean of the intercept is 0.008, indicating the uncertainty in the estimate of the mean.\n",
    "- **mcse_sd (Monte Carlo Standard Error for standard deviation)**: The MCSE for the standard deviation of the intercept is 0.005.\n",
    "- **ess_bulk (Effective Sample Size for bulk)**: The ESS for the bulk of the distribution for the intercept is 4053.0, indicating the number of effective samples used to calculate the bulk of the distribution.\n",
    "- **ess_tail (Effective Sample Size for tail)**: The ESS for the tail of the distribution for the intercept is 4153.0.\n",
    "- **r_hat**: The potential scale reduction factor on split chains (r_hat) for the intercept is 1.0, indicating convergence of the chains (values close to 1.0 indicate good mixing and convergence).\n",
    "\n",
    "\n",
    "**Bulk**: This usually refers to the central mass or the main body of the distribution. Effective Sample Size (ESS) for the bulk provides a measure of how many independent and identically distributed samples would be equivalent to the correlated samples in the central part of the posterior distribution. It is a way to quantify the amount of \"information\" that the sample contains about the central tendency of the parameter's distribution.\n",
    "\n",
    "**Tail**: This refers to the outer sections of the distribution, away from the median, often associated with the extremes or the tails of the distribution. The ESS for the tail provides a measure of the number of independent samples equivalent to the correlated samples in the tails of the posterior distribution. It is important for understanding the uncertainty in the extremes of the distribution, which can be critical for evaluating risks or rare events.\n",
    "\n",
    "In Bayesian analysis, having a high ESS for both the bulk and the tail of the distribution is important because it indicates that the Markov Chain Monte Carlo (MCMC) simulation has effectively explored the parameter space, providing a reliable approximation of the posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-movie",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"sepal_length ~ petal_length + petal_width\"\n",
    "\n",
    "with pm.Model() as model_2:\n",
    "    \n",
    "    pm.GLM.from_formula(formula, data=iris)\n",
    "    trace_2 = pm.sample(draws=1000, tune=500, chains=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-reaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace_2 ,figsize=(12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-cancellation",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pm.forestplot(trace_2, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(trace_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-boring",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model1_loo = az.loo(trace_1, model_1)\n",
    "#model2_loo = az.loo(trace_2, model_2)\n",
    "#df_comp_loo = az.compare({\"model_1\": trace_1, \"model_2\": trace_2})\n",
    "#az.plot_compare(df_comp_loo, insample_dev=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"sepal_length ~ sepal_width\"\n",
    "\n",
    "with pm.Model() as model_3:\n",
    "    \n",
    "    pm.GLM.from_formula(formula, data=iris)\n",
    "    trace_3 = pm.sample(draws=1000, tune=500, chains=12)\n",
    "    posterior_predictive = pm.fast_sample_posterior_predictive(trace_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(posterior_predictive['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-overhead",
   "metadata": {},
   "source": [
    "#### Now we have a distribution for each observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-village",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(posterior_predictive['y'][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(posterior_predictive['y'][:,119])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-fence",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(posterior_predictive['y'][:,119]) #12000 = 1000 draws * 12 chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb67abf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors=[]\n",
    "for index, observation in iris.iterrows():\n",
    "    error=posterior_predictive['y'][:,index] - observation['sepal_length']\n",
    "    errors.append(error)\n",
    "    \n",
    "error_distribution=np.array(errors).reshape(-1)\n",
    "error_distribution.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the error distribution\n",
    "pm.plot_posterior(error_distribution)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-mixture",
   "metadata": {},
   "source": [
    "### Assign prior distributions\n",
    "\n",
    "https://docs.pymc.io/en/latest/api/distributions/generated/pymc.Binomial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-going",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y = iris['sepal_length']\n",
    "X1 = iris['sepal_width']\n",
    "X2 = iris['petal_length']\n",
    "X3 = iris['petal_width']\n",
    "\n",
    "with pm.Model() as model_4:\n",
    "    beta0 = pm.Normal(\"beta0\", 0.0, 1.0) #Change to uniform distribution to see what happens (gamma, halfnormal, uniform, etc.)\n",
    "    beta1 = pm.Normal(\"beta1\", 0.0, 1.0)\n",
    "    beta2 = pm.Normal(\"beta2\", 0.0, 1.0)\n",
    "    beta3 = pm.Normal(\"beta3\", 0.0, 1.0)\n",
    "\n",
    "    mean_y = beta0 + beta1 * X1 + beta2 * X2 + beta3 * X3\n",
    " \n",
    "    pm.Normal(\"Y_obs\", mu=mean_y, sigma=1, observed=Y)\n",
    "    trace_4 = pm.sample(draws=100, tune=50, chains=2)\n",
    "    posterior_predictive = pm.fast_sample_posterior_predictive(trace_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-permit",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace_4 ,figsize=(15,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-ratio",
   "metadata": {},
   "source": [
    "The prior belief changes the outcome. That's how, we think of Bayes as a degree of belief"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-webcam",
   "metadata": {},
   "source": [
    "#### Updating priors\n",
    "\n",
    "\n",
    "https://docs.pymc.io/en/v3/pymc-examples/examples/pymc3_howto/updating_priors.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-pennsylvania",
   "metadata": {},
   "source": [
    "We want to keep probability density of posterior draws, following function does so, by using kernel density estimation. Function takes samples, and convert them into distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_posterior(param, samples):\n",
    "    smin, smax = np.min(samples), np.max(samples)\n",
    "    width = smax - smin\n",
    "    x = np.linspace(smin, smax, 100)\n",
    "    y = stats.gaussian_kde(samples)(x)\n",
    "\n",
    "    # what was never sampled should have a small probability but not 0,\n",
    "    # so we'll extend the domain and use linear approximation of density on it\n",
    "    \n",
    "    x = np.concatenate([[x[0] - 3 * width], x, [x[-1] + 3 * width]])\n",
    "    y = np.concatenate([[0], y, [0]])\n",
    "    return Interpolated(param, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-referral",
   "metadata": {},
   "source": [
    "Store means of coefficients, from the posterior draws of the model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-siemens",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta0_true = np.mean(trace_4.get_values('beta0'))\n",
    "beta1_true = np.mean(trace_4.get_values('beta1'))\n",
    "beta2_true = np.mean(trace_4.get_values('beta2'))\n",
    "beta3_true = np.mean(trace_4.get_values('beta3'))\n",
    "\n",
    "print(beta0_true,beta1_true,beta2_true,beta3_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c722b5ae-d4bd-4fc4-a68d-2dcffc7eea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trace_4.get_values('beta0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-child",
   "metadata": {},
   "source": [
    "Now we will use posterior draws of previous model as priors of a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-internship",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc3 import Model, Normal, Slice, sample\n",
    "from scipy import stats\n",
    "from pymc3.distributions import Interpolated\n",
    "\n",
    "traces =  [trace_4]\n",
    "\n",
    "model = Model()\n",
    "with model:\n",
    "    # Priors are posteriors from previous iteration\n",
    "    beta0 = from_posterior(\"beta0\", trace_4[\"beta0\"])\n",
    "    beta1 = from_posterior(\"beta1\", trace_4[\"beta1\"])\n",
    "    beta2 = from_posterior(\"beta2\", trace_4[\"beta2\"])\n",
    "    beta3 = from_posterior(\"beta3\", trace_4[\"beta3\"])\n",
    "\n",
    "    # Expected value of outcome\n",
    "    mean_y = beta0 + beta1 * X1 + beta2 * X2 + beta3 * X3\n",
    "\n",
    "    # Likelihood (sampling distribution) of observations\n",
    "    Y_obs = Normal(\"Y_obs\", mu=mean_y, sigma=1, observed=Y)\n",
    "\n",
    "    # draw 100 posterior samples\n",
    "    trace = pm.sample(draws=100, tune=50, chains=2)\n",
    "\n",
    "    traces.append(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-suite",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Posterior distributions after \" + str(len(traces)) + \" iterations.\")\n",
    "cmap = mpl.cm.autumn\n",
    "for param in [\"beta0\", \"beta1\", \"beta2\", \"beta3\"]:\n",
    "    plt.figure(figsize=(8, 2))\n",
    "    for update_i, trace in enumerate(traces):\n",
    "        samples = trace[param]\n",
    "        smin, smax = np.min(samples), np.max(samples)\n",
    "        x = np.linspace(smin, smax, 100)\n",
    "        y = stats.gaussian_kde(samples)(x)\n",
    "        plt.plot(x, y, color=cmap(1 - update_i / len(traces))) #in each step color gets from yellow to red\n",
    "    plt.axvline({\"beta0\": beta0_true, \"beta1\": beta1_true, \"beta2\": beta2_true, \"beta3\": beta3_true}[param], c=\"k\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(param)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e762ced",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "\n",
    "    model = Model()\n",
    "    with model:\n",
    "        # Priors are posteriors from previous iteration\n",
    "        beta0 = from_posterior(\"beta0\", traces[i][\"beta0\"])\n",
    "        beta1 = from_posterior(\"beta1\", traces[i][\"beta1\"])\n",
    "        beta2 = from_posterior(\"beta2\", traces[i][\"beta2\"])\n",
    "        beta3 = from_posterior(\"beta3\", traces[i][\"beta3\"])\n",
    "\n",
    "        # Expected value of outcome\n",
    "        mean_y = beta0 + beta1 * X1 + beta2 * X2 + beta3 * X3\n",
    "\n",
    "        # Likelihood (sampling distribution) of observations\n",
    "        Y_obs = Normal(\"Y_obs\", mu=mean_y, sigma=1, observed=Y)\n",
    "\n",
    "        # draw 10000 posterior samples\n",
    "        trace = pm.sample(draws=100, tune=50, chains=2)\n",
    "        traces.append(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44304bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta0_true = np.mean(traces[1].get_values('beta0'))\n",
    "beta1_true = np.mean(traces[1].get_values('beta1'))\n",
    "beta2_true = np.mean(traces[1].get_values('beta2'))\n",
    "beta3_true = np.mean(traces[1].get_values('beta3'))\n",
    "\n",
    "\n",
    "print(\"Posterior distributions after \" + str(len(traces)) + \" iterations.\")\n",
    "cmap = mpl.cm.autumn\n",
    "for param in [\"beta0\", \"beta1\", \"beta2\", \"beta3\"]:\n",
    "    plt.figure(figsize=(8, 2))\n",
    "    for update_i, trace in enumerate(traces):\n",
    "        samples = trace[param]\n",
    "        smin, smax = np.min(samples), np.max(samples)\n",
    "        x = np.linspace(smin, smax, 100)\n",
    "        y = stats.gaussian_kde(samples)(x)\n",
    "        plt.plot(x, y, color=cmap(1 - update_i / len(traces))) #in each step color gets from yellow to red\n",
    "    plt.axvline({\"beta0\": beta0_true, \"beta1\": beta1_true, \"beta2\": beta2_true, \"beta3\": beta3_true}[param], c=\"k\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(param)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da34f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a79b470",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces[1].varnames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d618ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_trace = traces[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d209d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(final_trace)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-kuwait",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-sheet",
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept_mean = np.mean(final_trace.get_values('beta0')) \n",
    "beta_1_mean = np.mean(final_trace.get_values('beta1')) \n",
    "beta_2_mean = np.mean(final_trace.get_values('beta2')) \n",
    "beta_3_mean = np.mean(final_trace.get_values('beta3')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-ethics",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_Y = {}\n",
    "for X1_dynamic in range(0,5):\n",
    "    pred_mean = intercept_mean + beta_1_mean * X1_dynamic + beta_2_mean * X2.mean() + beta_3_mean * X3.mean()\n",
    "    Y_pred = np.random.normal(pred_mean, sd_mean, size=100)\n",
    "    predicted_Y.update({X1_dynamic: Y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-narrative",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Draw a forest plot of predicted Y values\n",
    "pm.forestplot(predicted_Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pm.hdi(predicted_Y[4], hdi_prob=0.94)) #Change the hdi limitsY"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
